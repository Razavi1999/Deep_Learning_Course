{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eccd33ca96df4d12b539965615050016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d26b5360d2749898c82e939c117f404",
              "IPY_MODEL_9581d8a8e8ae41bb93f0b8f86f02205d",
              "IPY_MODEL_c040ae8947554763baffb6f2a2b111c6"
            ],
            "layout": "IPY_MODEL_483fe8486b8f4220b6057d4731c7fbc2"
          }
        },
        "5d26b5360d2749898c82e939c117f404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187178454f004871a5d34bd4fa69d362",
            "placeholder": "​",
            "style": "IPY_MODEL_7e659f3e603a4641a23513f3c53c518c",
            "value": "config.json: 100%"
          }
        },
        "9581d8a8e8ae41bb93f0b8f86f02205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3193675cf8bd49e89a27a5b5a83938fd",
            "max": 434,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2631c7752532472598b3df6996cce551",
            "value": 434
          }
        },
        "c040ae8947554763baffb6f2a2b111c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363842c27ae843eba2a4f8fc8c7aeb80",
            "placeholder": "​",
            "style": "IPY_MODEL_5c4ff7754b944eb7affca6c87d3c37f7",
            "value": " 434/434 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "483fe8486b8f4220b6057d4731c7fbc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187178454f004871a5d34bd4fa69d362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e659f3e603a4641a23513f3c53c518c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3193675cf8bd49e89a27a5b5a83938fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2631c7752532472598b3df6996cce551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "363842c27ae843eba2a4f8fc8c7aeb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4ff7754b944eb7affca6c87d3c37f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "910f939113aa4183861deabfbed11e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4141f62c064f46e08783a65d02287f60",
              "IPY_MODEL_3b809a022f704ef49651ea7e9e5a0e80",
              "IPY_MODEL_e120fe97d3e748b58d3e2fa03a389750"
            ],
            "layout": "IPY_MODEL_fea3c14c331648508646430de54fb3d9"
          }
        },
        "4141f62c064f46e08783a65d02287f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a2450e0c163494e93b6397f11ed47b0",
            "placeholder": "​",
            "style": "IPY_MODEL_e7c9c4074c384b47973a10aa15826ce6",
            "value": "vocab.txt: 100%"
          }
        },
        "3b809a022f704ef49651ea7e9e5a0e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27515d2ab80e4cba86e4e71ac384f6f9",
            "max": 1215509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7acfab0784e42c2b0c5c867c30f7bdb",
            "value": 1215509
          }
        },
        "e120fe97d3e748b58d3e2fa03a389750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c7487c29e441a390188c5cc0140f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_938e1d1604634782848fed8e37a6a427",
            "value": " 1.22M/1.22M [00:00&lt;00:00, 9.60MB/s]"
          }
        },
        "fea3c14c331648508646430de54fb3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a2450e0c163494e93b6397f11ed47b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c9c4074c384b47973a10aa15826ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27515d2ab80e4cba86e4e71ac384f6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7acfab0784e42c2b0c5c867c30f7bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17c7487c29e441a390188c5cc0140f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938e1d1604634782848fed8e37a6a427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use ParsBert"
      ],
      "metadata": {
        "id": "y-ew1AlT8s_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install necessary libraries\n",
        "# !pip install transformers\n",
        "# !pip install hazm"
      ],
      "metadata": {
        "id": "WEBC_XxstWkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAiKaxOAtUIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "eccd33ca96df4d12b539965615050016",
            "5d26b5360d2749898c82e939c117f404",
            "9581d8a8e8ae41bb93f0b8f86f02205d",
            "c040ae8947554763baffb6f2a2b111c6",
            "483fe8486b8f4220b6057d4731c7fbc2",
            "187178454f004871a5d34bd4fa69d362",
            "7e659f3e603a4641a23513f3c53c518c",
            "3193675cf8bd49e89a27a5b5a83938fd",
            "2631c7752532472598b3df6996cce551",
            "363842c27ae843eba2a4f8fc8c7aeb80",
            "5c4ff7754b944eb7affca6c87d3c37f7",
            "910f939113aa4183861deabfbed11e48",
            "4141f62c064f46e08783a65d02287f60",
            "3b809a022f704ef49651ea7e9e5a0e80",
            "e120fe97d3e748b58d3e2fa03a389750",
            "fea3c14c331648508646430de54fb3d9",
            "3a2450e0c163494e93b6397f11ed47b0",
            "e7c9c4074c384b47973a10aa15826ce6",
            "27515d2ab80e4cba86e4e71ac384f6f9",
            "a7acfab0784e42c2b0c5c867c30f7bdb",
            "17c7487c29e441a390188c5cc0140f1e",
            "938e1d1604634782848fed8e37a6a427"
          ]
        },
        "outputId": "6f99dc12-f29e-4611-d563-8b11163156cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eccd33ca96df4d12b539965615050016"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "910f939113aa4183861deabfbed11e48"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from hazm import Normalizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "Vl0KExkXXfOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive' , force_remount=True)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path1 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/anger.csv'\n",
        "file_path2 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/disgust.csv'\n",
        "file_path3 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/fear.csv'\n",
        "\n",
        "file_path4 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/joy.csv'\n",
        "file_path5 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/sad.csv'\n",
        "file_path6 = '/content/drive/MyDrive/persian-tweets-emotional-dataset/surprise.csv'\n",
        "\n",
        "\n",
        "df1 = pd.read_csv(file_path1)\n",
        "df2 = pd.read_csv(file_path2)\n",
        "df3 = pd.read_csv(file_path3)\n",
        "\n",
        "df4 = pd.read_csv(file_path4)\n",
        "df5 = pd.read_csv(file_path5)\n",
        "df6 = pd.read_csv(file_path6)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index = True)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVSghD02Xi6a",
        "outputId": "719b5361-0551-40cb-d3e9-ff18b294bc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df5.sample(20)"
      ],
      "metadata": {
        "id": "q8HLSs3WY8rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['و', 'در', 'به' ,\n",
        "             'از' , 'که' , 'این' , 'است',\n",
        "             'این' , 'می' , 'را' , 'با' , 'های' , 'برای' , 'آن' , 'یک' ,\n",
        "             'برای' , 'های' ,\n",
        "             'خود' , 'ها' , 'کرد' , 'شد' , 'ای' , 'تا' ,\n",
        "             'کند' , 'بر' , 'بود' , 'گفت' ,\n",
        "             'نیز' , 'وی' , 'هم' , 'کنند' , 'دارد' , 'ما' , 'کرده' ,\n",
        "             'یا' , 'اما' , 'باید' ,\n",
        "             'دو' , 'اند' , 'هر' , 'خواهد' , 'او' , 'مورد' , 'باشد' ,\n",
        "             'دیگر' , 'بین' , 'پیش' ,\n",
        "             'پس' , 'اگر' , 'همه' , 'صورت' , 'یکی' , 'هستند' , 'من' , 'دهد' ,\n",
        "             'نیست' , 'استفاده' ,\n",
        "             'داد' , 'داشته' , 'راه' , 'داشت' , 'چه' , 'همچنین' ,\n",
        "             'کردند' , 'داده' , 'بوده' , 'دارند' ,\n",
        "             'همین' , 'سوی' , 'شوند' , 'بسیار' , 'روی' , 'گرفته‌اند' ,\n",
        "             'هایی' , 'تواند' , 'حتی' , 'اینکه' ,\n",
        "             'این‌که' , 'ولی' , 'توسط' , 'چنین' , 'برخی' ,\n",
        "             'درباره' , 'گیرد' , 'گفته' , 'آنان' ,\n",
        "             'بار' , 'طور' , 'گرفت' , 'دهند' , 'گذاری' , 'بسیاری' ,\n",
        "             'طی' , 'بودند' , 'براساس' , 'شدند' ,\n",
        "             'باشند' , 'چون' , 'قابل' , 'گوید' , 'دیگری' , 'همان' , 'خواهند' ,\n",
        "             'طریق' , 'آمده' , 'تحت' ,\n",
        "             'گیری' , 'جای' , 'سازی' , 'کنم' , 'زیر' , 'توانند' , 'ضمن' ,\n",
        "             'فقط' , 'بودن' , 'آید' ,\n",
        "             'اش' , 'ام' , 'ات' , 'آورد' , 'امان' , 'اتان' , 'اشان' ,\n",
        "             'آنچه' , 'ریزی' ,\n",
        "             'بنابراین' , 'بعضی' , 'برخی' , 'دادند' , 'داشتند' ,\n",
        "             'زیر' , 'روی' , 'سری' , 'توی' , 'جلوی' ,\n",
        "             'پیش' , 'عقب' , 'بالای' , 'خارج' , 'وسط' , 'بیرون' , 'سوی' , 'کنار' ,\n",
        "             'نزد' , 'دنبال' ,\n",
        "             'حدود' , 'برابر' , 'اثر' , 'علت' , 'عنوان' , 'قصد' , 'جدا' ,\n",
        "             'کی' , 'که' , 'چیست' ,\n",
        "             'هست' , 'کجا' , 'کجاست' , 'چطور' , 'کدام' , 'آیا' , 'مگر' ,\n",
        "             'چندین' , 'یک' , 'چیزی' ,\n",
        "             'دیگر' , 'کسی' , 'چیز' , 'جا' , 'کس' , 'لطفا' , 'تان' , 'مان' ,\n",
        "             'هنگامی' , 'وقتیکه' ,\n",
        "             'مدتی' ,\n",
        "             'آنکه' , 'انکه' , 'خواهشا' , 'وقتیکه'\n",
        "             ]\n",
        "\n",
        "# print('----------- length of stopwords ---------------')\n",
        "# print(len(stopwords))\n",
        "# print('-----------------------------------------------')\n",
        "# print('مدتی' in stopwords)"
      ],
      "metadata": {
        "id": "s2m9swJQ_4IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_mapping = {\n",
        "    '😊': 'خندان',\n",
        "    '😢': 'غمگین',\n",
        "    '😂': 'خنده',\n",
        "    '😍': 'عاشق',\n",
        "    '❤️': 'عشق',\n",
        "    '👍': 'خوب',\n",
        "    '👎': 'بد',\n",
        "    '🙏': 'دعا',\n",
        "    '🔥': 'آتش',\n",
        "    '🔴' : 'قرمز' ,\n",
        "    '🟡' : 'زرد' ,\n",
        "    '✊' : 'مشت' ,\n",
        "    '💥' : 'هیجان' ,\n",
        "    '📡' : 'فوری' ,\n",
        "    '⬅️' : 'تماشا' ,\n",
        "    '🇮🇷' : 'ایران' ,\n",
        "    '✌' : 'دوباره' ,\n",
        "    '💔': 'شکسته',\n",
        "    '🌸': 'گل',\n",
        "    '🌞': 'خورشید',\n",
        "    '🌈': 'رنگین‌کمان',\n",
        "    '🎉': 'تبریک',\n",
        "    '🤗': 'دوستانه',\n",
        "    '🤔': 'تفکر',\n",
        "    '😜': 'شوخی'\n",
        "}"
      ],
      "metadata": {
        "id": "7q492y98GRXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess_tweet"
      ],
      "metadata": {
        "id": "Yb5JkDOf_0JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# df = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)"
      ],
      "metadata": {
        "id": "s-5KVfT4q-uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from hazm import Normalizer, Stemmer, word_tokenize\n",
        "\n",
        "\n",
        "normalizer = Normalizer()\n",
        "stemmer = Stemmer()\n",
        "\n",
        "\n",
        "def preprocess_tweet(tweet , stop_words , emoji_mapping):\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|<\\S+>', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    tweet = re.sub(r'(.)\\1+', r'\\1', tweet)\n",
        "\n",
        "    tweet = normalizer.normalize(tweet)\n",
        "    words = word_tokenize(tweet)\n",
        "\n",
        "    words = [word for word in words if word not in stopwords]\n",
        "\n",
        "\n",
        "    for emoji, text in emoji_mapping.items():\n",
        "        tweet = tweet.replace(emoji, text)\n",
        "\n",
        "    stemmed_words = [word for word in words]\n",
        "\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "df['preprocessed_tweet'] = df['tweet'].apply(lambda x: preprocess_tweet(x, stopwords, emoji_mapping))\n",
        "\n",
        "# df.sample(7)[['hashtags' , 'tweet', 'emotion', 'preprocessed_tweet']]"
      ],
      "metadata": {
        "id": "0PFQo_UpdGfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing"
      ],
      "metadata": {
        "id": "oe55H4j7tfN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "\n",
        "def tokenize_and_pad(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
        "    return tokens[\"input_ids\"]\n",
        "\n",
        "\n",
        "df['ids'] = df['preprocessed_tweet'].apply(tokenize_and_pad)\n",
        "# df.sample(7)[['hashtags' , 'tweet', 'emotion', 'preprocessed_tweet' , 'ids']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvD__WkYthfq",
        "outputId": "72b5a251-8dc9-43ca-b5a4-d49d589c9d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.sample(7)[['hashtags' , 'tweet',  'preprocessed_tweet' , 'emotion' , 'ids']]\n",
        "\n",
        "# df.iloc[69062]"
      ],
      "metadata": {
        "id": "Fr4-U0nyu_tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CustomDataSet"
      ],
      "metadata": {
        "id": "Aa20Lp4c0C6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, temp_data = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "train_data.reset_index(drop=True, inplace=True)\n",
        "val_data.reset_index(drop=True, inplace=True)\n",
        "test_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "r7FRHV5N0sfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "emotion_to_label = {\n",
        "    'anger': 0,\n",
        "    'disgust': 1,\n",
        "    'fear': 2,\n",
        "    'joy': 3,\n",
        "    'sad': 4,\n",
        "    'surprise': 5\n",
        "}\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['preprocessed_tweet']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        label = emotion_to_label[emotion]\n",
        "        tokens = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "\n",
        "        input_ids = tokens\n",
        "        # padding_length = self.max_length - input_ids.shape[1]\n",
        "        # if padding_length > 0:\n",
        "        #     input_ids = torch.cat([input_ids, torch.zeros((1, padding_length), dtype=torch.long)], dim=1)\n",
        "\n",
        "\n",
        "\n",
        "        return {\n",
        "            'text' : text ,\n",
        "            'input_ids': input_ids,\n",
        "            'label': torch.tensor(label)\n",
        "        }\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "\n",
        "train_dataset = CustomDataset(train_data, tokenizer , max_length=32)\n",
        "val_dataset   = CustomDataset(val_data  , tokenizer , max_length=32)\n",
        "test_dataset  = CustomDataset(test_data,  tokenizer , max_length=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkjkJFw20Flb",
        "outputId": "893f3ff7-af61-443e-9708-a10da958bd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN_LSTM"
      ],
      "metadata": {
        "id": "S8ysfKvc2ozN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = train_data['preprocessed_tweet'].apply(tokenize_and_pad)\n",
        "\n",
        "vocab_size = len(ids)\n",
        "\n",
        "print(f'vocab_size  : {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXuLjvyAGRwT",
        "outputId": "445ff84c-3efd-4212-bb29-107157ccbd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size  : 79680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.5, pad_idx=0):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=3)\n",
        "\n",
        "        self.lstm = nn.LSTM(100, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # print(f'embedded shape : {embedded.shape}')\n",
        "        conv_out = self.conv(embedded.permute(0, 2, 1))\n",
        "        # Conv1d shape : (batch_size, embedding_dim, seq_len)\n",
        "\n",
        "        lstm_out, _ = self.lstm(conv_out.permute(0, 2, 1))\n",
        "        # LSTM shape : (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        # Concatenate the final hidden state from both directions\n",
        "        hidden = torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1)\n",
        "\n",
        "        dropped = self.dropout(hidden)\n",
        "\n",
        "        output = self.fc(dropped)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "HULzr1aiF-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# just testing the CNN-LSTM model for lr = 0.1 , num_epochs = 10"
      ],
      "metadata": {
        "id": "1pU2F0qIm-qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "vocab_size = vocab_size\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN_LSTM(vocab_size = vocab_size , embedding_dim = 120 , hidden_dim = 6, output_dim = 6, dropout = 0.1).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids']['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        text = batch['text']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = input_ids.squeeze(1)\n",
        "        outputs = model(input_ids).to(device)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch2 in val_loader:\n",
        "            labels , inputs = batch2['label'].to(device) , batch2['input_ids']['input_ids'].to(device)\n",
        "            # print(f'inputs shape : {inputs.shape}')\n",
        "\n",
        "            inputs = inputs.squeeze(1)\n",
        "\n",
        "            outputs = model(inputs).to(device)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_loader)\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {100 * train_accuracy:.2f}%, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {100 * val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW89ASIwzsAr",
        "outputId": "7e4ac634-5a12-4583-f5c5-ecab5bbe76b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.2679, Train Accuracy: 51.30%, Val Loss: 0.7791, Val Accuracy: 75.22%\n",
            "Epoch [2/10], Train Loss: 0.5968, Train Accuracy: 81.05%, Val Loss: 0.4489, Val Accuracy: 85.00%\n",
            "Epoch [3/10], Train Loss: 0.4106, Train Accuracy: 86.71%, Val Loss: 0.3917, Val Accuracy: 86.61%\n",
            "Epoch [4/10], Train Loss: 0.3414, Train Accuracy: 88.86%, Val Loss: 0.3836, Val Accuracy: 87.05%\n",
            "Epoch [5/10], Train Loss: 0.2990, Train Accuracy: 90.15%, Val Loss: 0.3835, Val Accuracy: 87.19%\n",
            "Epoch [6/10], Train Loss: 0.2638, Train Accuracy: 91.40%, Val Loss: 0.3902, Val Accuracy: 87.11%\n",
            "Epoch [7/10], Train Loss: 0.2339, Train Accuracy: 92.48%, Val Loss: 0.3964, Val Accuracy: 87.30%\n",
            "Epoch [8/10], Train Loss: 0.2130, Train Accuracy: 93.02%, Val Loss: 0.4128, Val Accuracy: 87.22%\n",
            "Epoch [9/10], Train Loss: 0.1940, Train Accuracy: 93.73%, Val Loss: 0.4252, Val Accuracy: 87.15%\n",
            "Epoch [10/10], Train Loss: 0.1798, Train Accuracy: 94.20%, Val Loss: 0.4368, Val Accuracy: 87.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "labels_cpu = labels.cpu()\n",
        "numpy_labels = labels_cpu.numpy()\n",
        "\n",
        "predicted_cpu = predicted.cpu()\n",
        "numpy_predicted = predicted_cpu.numpy()\n",
        "\n",
        "print(classification_report(numpy_labels , numpy_predicted))\n",
        "\n",
        "wrong_samples = {i: [] for i in range(6)}\n",
        "for i, (pred, target) in enumerate(zip(numpy_predicted, numpy_labels)):\n",
        "    if pred != target:\n",
        "        wrong_samples[target].append(val_dataset[i])\n",
        "\n",
        "\n",
        "for label, samples in wrong_samples.items():\n",
        "    print(f\"Samples for class {label} (predicted wrongly):\")\n",
        "    for sample in samples[:5]:\n",
        "        print(sample)"
      ],
      "metadata": {
        "id": "FKwiPlQ1PEft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1cdb2a-458f-4287-d60a-50220235e61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94         9\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         7\n",
            "           4       0.90      1.00      0.95         9\n",
            "           5       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.97        31\n",
            "   macro avg       0.98      0.98      0.98        31\n",
            "weighted avg       0.97      0.97      0.97        31\n",
            "\n",
            "Samples for class 0 (predicted wrongly):\n",
            "{'text': 'ینی اگه شونو الان پاشه بیاد لایو می\\u200cگیرم دست میندازم دهن خودمو جر میدم شب بیا فردا بیا دلم تنگ گشته #HBDtoSHOWNU #셔누 #찬란하고_애틋한_셔누ayo', 'input_ids': {'input_ids': tensor([[    2, 41914, 12915, 28773,  1154,  4358, 10145,  1177, 18047, 26947,\n",
            "         15566,  2166, 38359,  2782, 24858, 66003,  6990, 26450,  2458, 15115,\n",
            "          5528, 15115, 11657,  6217, 14508,     1, 86372,  1211, 16043, 16406,\n",
            "         74869,     4]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])}, 'label': tensor(0)}\n",
            "Samples for class 1 (predicted wrongly):\n",
            "Samples for class 2 (predicted wrongly):\n",
            "Samples for class 3 (predicted wrongly):\n",
            "Samples for class 4 (predicted wrongly):\n",
            "Samples for class 5 (predicted wrongly):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Hyperparameters"
      ],
      "metadata": {
        "id": "xN02OVdKUVyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
        "tokenized_texts = tokenizer(df['preprocessed_tweet'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "AzMrPnSuX28g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "batch_sizes = [8, 64]\n",
        "learning_rates = [0.001, 0.0001]\n",
        "optimizers = {'Adam': Adam, 'SGD': SGD}\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            data = batch['input_ids']['input_ids'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "\n",
        "            data = data.squeeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch2 in val_loader:\n",
        "                data, targets = batch2['input_ids']['input_ids'].to(device) , batch2['label'].to(device)\n",
        "\n",
        "                data = data.squeeze(1)\n",
        "                outputs = model(data)\n",
        "                val_loss += criterion(outputs, targets).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss}')\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "vocab_size = vocab_size\n",
        "\n",
        "\n",
        "model = CNN_LSTM(vocab_size = vocab_size, embedding_dim=120, hidden_dim=6, output_dim=6, dropout=0.1).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for opt_name, Optimizer in optimizers.items():\n",
        "            print(f'Testing batch size {batch_size}, learning rate {lr}, optimizer {opt_name}')\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "            optimizer = Optimizer(model.parameters(), lr=lr)\n",
        "\n",
        "            train_model(model, criterion, optimizer, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "LIUIPkgCUUva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5c2c53-7cc8-4609-ebb2-60c0a7246f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing batch size 8, learning rate 0.001, optimizer Adam\n",
            "Epoch 1, Validation Loss: 0.8043544072371263\n",
            "Epoch 2, Validation Loss: 0.43163798099800527\n",
            "Epoch 3, Validation Loss: 0.3957567123592004\n",
            "Epoch 4, Validation Loss: 0.39267775721235815\n",
            "Epoch 5, Validation Loss: 0.42428676159238327\n",
            "Epoch 6, Validation Loss: 0.3761785085391175\n",
            "Epoch 7, Validation Loss: 0.3784258096263959\n",
            "Epoch 8, Validation Loss: 0.3710087759316072\n",
            "Epoch 9, Validation Loss: 0.376442159951658\n",
            "Epoch 10, Validation Loss: 0.3807416510470277\n",
            "Testing batch size 8, learning rate 0.001, optimizer SGD\n",
            "Epoch 1, Validation Loss: 0.37916292414668346\n",
            "Epoch 2, Validation Loss: 0.3787278924111303\n",
            "Epoch 3, Validation Loss: 0.37899338479879985\n",
            "Epoch 4, Validation Loss: 0.3789093378608903\n",
            "Epoch 5, Validation Loss: 0.3792588109189605\n",
            "Epoch 6, Validation Loss: 0.37944738451648713\n",
            "Epoch 7, Validation Loss: 0.3794607352491442\n",
            "Epoch 8, Validation Loss: 0.37946522184761594\n",
            "Epoch 9, Validation Loss: 0.3795349446439569\n",
            "Epoch 10, Validation Loss: 0.3797325296128833\n",
            "Testing batch size 8, learning rate 0.0001, optimizer Adam\n",
            "Epoch 1, Validation Loss: 0.37856575608794035\n",
            "Epoch 2, Validation Loss: 0.3779086897288078\n",
            "Epoch 3, Validation Loss: 0.3798542661502814\n",
            "Epoch 4, Validation Loss: 0.3826662199086529\n",
            "Epoch 5, Validation Loss: 0.38584909198750333\n",
            "Epoch 6, Validation Loss: 0.38791018015252415\n",
            "Epoch 7, Validation Loss: 0.3906059446503649\n",
            "Epoch 8, Validation Loss: 0.3936557308554167\n",
            "Epoch 9, Validation Loss: 0.3976044348194394\n",
            "Epoch 10, Validation Loss: 0.3999883540206706\n",
            "Testing batch size 8, learning rate 0.0001, optimizer SGD\n",
            "Epoch 1, Validation Loss: 0.3999831641494244\n",
            "Epoch 2, Validation Loss: 0.3999735728420734\n",
            "Epoch 3, Validation Loss: 0.4000140032599114\n",
            "Epoch 4, Validation Loss: 0.40008056516917034\n",
            "Epoch 5, Validation Loss: 0.40017011654302737\n",
            "Epoch 6, Validation Loss: 0.4002574781257125\n",
            "Epoch 7, Validation Loss: 0.40034038282058143\n",
            "Epoch 8, Validation Loss: 0.4004336079739692\n",
            "Epoch 9, Validation Loss: 0.4005293585739418\n",
            "Epoch 10, Validation Loss: 0.4006117265545307\n",
            "Testing batch size 64, learning rate 0.001, optimizer Adam\n",
            "Epoch 1, Validation Loss: 0.39020855266954646\n",
            "Epoch 2, Validation Loss: 0.39524700927584533\n",
            "Epoch 3, Validation Loss: 0.3974322023796303\n",
            "Epoch 4, Validation Loss: 0.4016620872864843\n",
            "Epoch 5, Validation Loss: 0.4145132815413302\n",
            "Epoch 6, Validation Loss: 0.4116967447185317\n",
            "Epoch 7, Validation Loss: 0.4185481980734364\n",
            "Epoch 8, Validation Loss: 0.415433995758688\n",
            "Epoch 9, Validation Loss: 0.4236420882897004\n",
            "Epoch 10, Validation Loss: 0.43036127240298183\n",
            "Testing batch size 64, learning rate 0.001, optimizer SGD\n",
            "Epoch 1, Validation Loss: 0.43038809064297034\n",
            "Epoch 2, Validation Loss: 0.43038551124364305\n",
            "Epoch 3, Validation Loss: 0.4304033576734572\n",
            "Epoch 4, Validation Loss: 0.4304814673127742\n",
            "Epoch 5, Validation Loss: 0.43056812347563284\n",
            "Epoch 6, Validation Loss: 0.43071756874049844\n",
            "Epoch 7, Validation Loss: 0.4308298737351788\n",
            "Epoch 8, Validation Loss: 0.430917936205531\n",
            "Epoch 9, Validation Loss: 0.4310649225706828\n",
            "Epoch 10, Validation Loss: 0.4312045439744795\n",
            "Testing batch size 64, learning rate 0.0001, optimizer Adam\n",
            "Epoch 1, Validation Loss: 0.43200492550873887\n",
            "Epoch 2, Validation Loss: 0.4339544079240474\n",
            "Epoch 3, Validation Loss: 0.43615950698126627\n",
            "Epoch 4, Validation Loss: 0.43838081685774155\n",
            "Epoch 5, Validation Loss: 0.44140881934728704\n",
            "Epoch 6, Validation Loss: 0.44261061160840803\n",
            "Epoch 7, Validation Loss: 0.4436865848119698\n",
            "Epoch 8, Validation Loss: 0.44615800295795144\n",
            "Epoch 9, Validation Loss: 0.4480265993728984\n",
            "Epoch 10, Validation Loss: 0.448641151064934\n",
            "Testing batch size 64, learning rate 0.0001, optimizer SGD\n",
            "Epoch 1, Validation Loss: 0.44866100865202907\n",
            "Epoch 2, Validation Loss: 0.44869133698956926\n",
            "Epoch 3, Validation Loss: 0.44871411824276325\n",
            "Epoch 4, Validation Loss: 0.448739744410668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "\n",
        "batch_sizes = [8, 64]\n",
        "learning_rates = [0.001, 0.0001]\n",
        "optimizers = {'Adam': Adam, 'SGD': SGD}\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Tracking training loss and accuracy\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        for batch in train_loader:\n",
        "            data = batch['input_ids']['input_ids'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "            data = data.squeeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += targets.size(0)\n",
        "            train_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                data = batch['input_ids']['input_ids'].to(device)\n",
        "                targets = batch['label'].to(device)\n",
        "                data = data.squeeze(1)\n",
        "\n",
        "                outputs = model(data)\n",
        "                val_loss += criterion(outputs, targets).item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        print(f'Epoch {epoch+1}, Validation Loss: {val_list:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "model = CNN_LSTM(vocab_size=vocab_size, embedding_dim=120, hidden_dim=6, output_dim=6, dropout=0.1).to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    for lr in learning_rates:\n",
        "        for opt_name, Optimizer in optimizers.items():\n",
        "            print(f'Testing batch size {batch_size}, learning rate {lr}, optimizer {opt_name}')\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_name)\n",
        "\n",
        "            optimizer = Optimizer(model.parameters(), lr=lr)\n",
        "            train_model(model, criterion, optimizer, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "QK-vlJYGvZ0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}