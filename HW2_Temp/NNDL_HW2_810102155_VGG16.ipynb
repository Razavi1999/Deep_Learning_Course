{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IWPGULlb93x"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLr-2PMVrcpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bb4f90-d62d-4f2f-b11c-388c65b356b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "-----------------------------------------------\n",
            "Number of files in /content/drive/MyDrive/NNDL_HW2_After_Augment/Train are : 2808\n",
            "---------------------------------------------------------------------------\n",
            "Number of files in /content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/Cats are : 100\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive' , force_remount=True)\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/'\n",
        "file1_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/'\n",
        "# file2_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/Dogs'\n",
        "\n",
        "files1 = [f for f in os.listdir(file1_path) if os.path.isfile(os.path.join(file1_path, f))]\n",
        "\n",
        "\n",
        "# print(f\"Number of files in {file1_path} Before Augmentation : {len(files1)}\")\n",
        "# print(f\"Number of files in {file2_path} Before Augmentation : {len(files2)}\")\n",
        "print('-----------------------------------------------')\n",
        "\n",
        "all_train_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train'\n",
        "train_path1 = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Cats/'\n",
        "train_path2 = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Dogs/'\n",
        "\n",
        "all_test_path = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/'\n",
        "\n",
        "train_files1 = [f for f in os.listdir(train_path1) if os.path.isfile(os.path.join(train_path1, f))]\n",
        "train_files2 = [f for f in os.listdir(train_path2) if os.path.isfile(os.path.join(train_path2, f))]\n",
        "\n",
        "# all_train_files = [f for f in os.listdir(all_train_path) if os.path.isfile(os.path.join(all_train_path, f))]\n",
        "print(f'Number of files in {all_train_path} are : {len(train_files1) + len(train_files2)}') # 2106\n",
        "\n",
        "print('---------------------------------------------------------------------------')\n",
        "\n",
        "test_path = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/Cats'\n",
        "test_path2 = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/Dogs'\n",
        "\n",
        "files2 = [f for f in os.listdir(test_path2) if os.path.isfile(os.path.join(test_path2, f))]\n",
        "files3 = [f for f in os.listdir(test_path)  if os.path.isfile(os.path.join(test_path, f))]\n",
        "print(f\"Number of files in {test_path} are : {len(files2) + len(files3)}\")\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfering files into their correspond directory"
      ],
      "metadata": {
        "id": "CWNO79iKdMvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "cat_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Cats'\n",
        "dog_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Dogs'\n",
        "train_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train'\n",
        "\n",
        "# parent_dir = '/content/drive/MyDrive/NNDL_HW2_After_Augment/'\n",
        "parent_dir_cats = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Train/Cats/'\n",
        "parent_dir_dogs = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Train/Dogs/'\n",
        "\n",
        "all_train_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train'\n",
        "train_path1 = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Cats/'\n",
        "train_path2 = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/Dogs/'\n",
        "\n",
        "parent_files_cats = [f for f in os.listdir(parent_dir_cats) if os.path.isfile(os.path.join(parent_dir_cats , f))]\n",
        "parent_files_dogs = [f for f in os.listdir(parent_dir_dogs) if os.path.isfile(os.path.join(parent_dir_dogs , f))]\n",
        "\n",
        "# Check if directories exist, create them if needed\n",
        "# os.makedirs(cat_path, exist_ok=True)\n",
        "# os.makedirs(dog_path, exist_ok =True)\n",
        "# os.makedirs(train_path , exist_ok = True)\n",
        "\n",
        "# for filename in parent_files_cats:\n",
        "#   src = os.path.join(parent_dir_cats , filename)\n",
        "#   dst = os.path.join(cat_path, filename)\n",
        "#   # print(f'src : {src} \\n')\n",
        "#   # print(f'dst : {dst} \\n')\n",
        "#   # print('-----------------------')\n",
        "\n",
        "#   shutil.move(src, dst)\n",
        "\n",
        "# for filename in parent_files_dogs:\n",
        "#   src = os.path.join(parent_dir_dogs , filename)\n",
        "#   dst = os.path.join(dog_path, filename)\n",
        "#   # print(f'src : {src} \\n')\n",
        "#   # print(f'dst : {dst} \\n')\n",
        "#   # print('-----------------------')\n",
        "\n",
        "#   shutil.move(src, dst)\n",
        "\n"
      ],
      "metadata": {
        "id": "cH6z3FX5PuWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbqSbed75J2"
      },
      "source": [
        "# Preprocessing and image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0lPwZa8f78mm",
        "outputId": "e914679b-8883-49a8-b3d3-f70c2a1b0da8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/Cats'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2da07109a621>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Iterate over all image files in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/Cats'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "\n",
        "file_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/'\n",
        "file1_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/Cats'\n",
        "file2_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/Dogs'\n",
        "\n",
        "# Define the augmentation parameters\n",
        "rotation_angle = 30\n",
        "zoom_range = (0.75, 1.25)\n",
        "\n",
        "# Function to perform image augmentation\n",
        "def augment_image(image_path , save_path):\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Horizontal flipping\n",
        "    flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    flipped_image.save(os.path.join(save_path, f\"flipped_{os.path.basename(image_path)}\"))\n",
        "\n",
        "    # Rotation\n",
        "    angle = random.randint(-rotation_angle, rotation_angle)\n",
        "    rotated_image = image.rotate(angle)\n",
        "    rotated_image.save(os.path.join(save_path, f\"rotated_{os.path.basename(image_path)}\"))\n",
        "\n",
        "    # Scaling or zooming\n",
        "    zoom_factor = random.uniform(zoom_range[0], zoom_range[1])\n",
        "    scaled_image = image.resize((int(image.width * zoom_factor), int(image.height * zoom_factor)))\n",
        "    scaled_image.save(os.path.join(save_path, f\"scaled_{os.path.basename(image_path)}\"))\n",
        "\n",
        "\n",
        "# Iterate over all image files in the directory\n",
        "for file_name in os.listdir(file1_path):\n",
        "    if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
        "        file_path = os.path.join(file1_path, file_name)\n",
        "        augment_image(file_path, file1_path)\n",
        "\n",
        "# Iterate over all image files in the directory\n",
        "for file_name in os.listdir(file2_path):\n",
        "    if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
        "        file_path = os.path.join(file2_path, file_name)\n",
        "        augment_image(file_path, file2_path)\n",
        "\n",
        "files1 = [f for f in os.listdir(file1_path) if os.path.isfile(os.path.join(file1_path, f))]\n",
        "files2 = [f for f in os.listdir(file2_path) if os.path.isfile(os.path.join(file2_path, f))]\n",
        "\n",
        "print(f\"Number of files in {file1_path} After Augmentation : {len(files1)}\")\n",
        "print(f\"Number of files in {file2_path} After Augmentation : {len(files2)}\")\n",
        "print('-----------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S13rZCUy1CZk"
      },
      "source": [
        "# VGG16 Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "9Nn_Jfd_W7-E",
        "outputId": "3cba7a90-cf7c-4f72-e01f-c10052f6c24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Found 3231 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "101/101 [==============================] - 2108s 21s/step - loss: 0.7326 - accuracy: 0.7481\n",
            "Epoch 2/10\n",
            "101/101 [==============================] - 2061s 20s/step - loss: 0.2422 - accuracy: 0.9003\n",
            "Epoch 3/10\n",
            "101/101 [==============================] - 2061s 20s/step - loss: 0.2081 - accuracy: 0.9124\n",
            "Epoch 4/10\n",
            "101/101 [==============================] - 2060s 20s/step - loss: 0.1580 - accuracy: 0.9366\n",
            "Epoch 5/10\n",
            "101/101 [==============================] - 2061s 20s/step - loss: 0.1327 - accuracy: 0.9508\n",
            "Epoch 6/10\n",
            "101/101 [==============================] - 2058s 20s/step - loss: 0.1167 - accuracy: 0.9573\n",
            "Epoch 7/10\n",
            " 63/101 [=================>............] - ETA: 12:58 - loss: 0.1418 - accuracy: 0.9439"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-045f46370eeb>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Unfreeze the last CONV block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Dense, Flatten\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # Define hyperparameters\n",
        "# initial_lr = 0.001\n",
        "# lr_decay_rate = 0.1\n",
        "# momentum = 0.9\n",
        "# batch_size = 32\n",
        "# epochs = 10\n",
        "\n",
        "# # Load pre-trained VGG16 model\n",
        "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Replace the FC layers with new ones for binary classification (dog vs cat)\n",
        "# x = Flatten()(base_model.output)\n",
        "# output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# # Freeze all layers except the new FC layers\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Compile the model\n",
        "# opt = SGD(learning_rate = initial_lr, momentum=momentum)\n",
        "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Data augmentation for training images\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "#                                    shear_range=0.2,\n",
        "#                                    zoom_range=0.2,\n",
        "#                                    horizontal_flip=True)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(file_path ,\n",
        "#                                                     target_size=(224, 224),\n",
        "#                                                     batch_size=batch_size,\n",
        "#                                                     class_mode='categorical')\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(train_generator, epochs=epochs)\n",
        "\n",
        "# # Unfreeze the last CONV block\n",
        "# for layer in model.layers[:15]:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Recompile the model to apply the changes\n",
        "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model again to fine-tune the last CONV layer block\n",
        "# model.fit(train_generator, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ePvVH7ox-6H"
      },
      "source": [
        "# VGG16 - With Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9PESLC8x7Km",
        "outputId": "f9b5ecf8-7418-4ef5-f853-d5c0ea75fa1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2247 images belonging to 2 classes.\n",
            "Found 561 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "225/225 [==============================] - 1240s 5s/step - loss: 148.6318 - accuracy: 0.7170 - val_loss: 34.8454 - val_accuracy: 0.8930\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 51s 228ms/step - loss: 106.1944 - accuracy: 0.8149 - val_loss: 263.6416 - val_accuracy: 0.6631\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 52s 232ms/step - loss: 45.4624 - accuracy: 0.8830 - val_loss: 48.9217 - val_accuracy: 0.8734\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 52.3235 - accuracy: 0.8825 - val_loss: 45.0187 - val_accuracy: 0.8752\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 51s 225ms/step - loss: 33.6519 - accuracy: 0.9110 - val_loss: 11.7384 - val_accuracy: 0.9572\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 52s 231ms/step - loss: 45.0672 - accuracy: 0.8905 - val_loss: 48.1747 - val_accuracy: 0.8752\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 49s 219ms/step - loss: 41.8637 - accuracy: 0.8923 - val_loss: 7.1751 - val_accuracy: 0.9733\n",
            "Epoch 8/50\n",
            "225/225 [==============================] - 51s 229ms/step - loss: 25.4866 - accuracy: 0.9226 - val_loss: 5.0428 - val_accuracy: 0.9768\n",
            "Epoch 9/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 24.8631 - accuracy: 0.9306 - val_loss: 78.4670 - val_accuracy: 0.8253\n",
            "Epoch 10/50\n",
            "225/225 [==============================] - 52s 233ms/step - loss: 28.8504 - accuracy: 0.9203 - val_loss: 22.0121 - val_accuracy: 0.9323\n",
            "Epoch 11/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 46.5368 - accuracy: 0.9101 - val_loss: 15.1806 - val_accuracy: 0.9519\n",
            "Epoch 12/50\n",
            "225/225 [==============================] - 50s 224ms/step - loss: 18.2002 - accuracy: 0.9484 - val_loss: 36.2310 - val_accuracy: 0.8913\n",
            "Epoch 13/50\n",
            "225/225 [==============================] - 52s 229ms/step - loss: 19.6861 - accuracy: 0.9408 - val_loss: 3.4084 - val_accuracy: 0.9804\n",
            "Epoch 14/50\n",
            "225/225 [==============================] - 50s 223ms/step - loss: 20.9992 - accuracy: 0.9364 - val_loss: 4.5770 - val_accuracy: 0.9804\n",
            "Epoch 15/50\n",
            "225/225 [==============================] - 52s 229ms/step - loss: 9.5520 - accuracy: 0.9684 - val_loss: 3.5643 - val_accuracy: 0.9875\n",
            "Epoch 16/50\n",
            "225/225 [==============================] - 51s 227ms/step - loss: 18.0528 - accuracy: 0.9479 - val_loss: 5.7334 - val_accuracy: 0.9715\n",
            "Epoch 17/50\n",
            "225/225 [==============================] - 51s 225ms/step - loss: 10.3054 - accuracy: 0.9653 - val_loss: 42.7487 - val_accuracy: 0.8752\n",
            "Epoch 18/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 10.5164 - accuracy: 0.9684 - val_loss: 14.2344 - val_accuracy: 0.9412\n",
            "Epoch 19/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 42.5630 - accuracy: 0.9208 - val_loss: 0.6521 - val_accuracy: 0.9947\n",
            "Epoch 20/50\n",
            "225/225 [==============================] - 52s 233ms/step - loss: 8.8267 - accuracy: 0.9684 - val_loss: 0.8171 - val_accuracy: 0.9947\n",
            "Epoch 21/50\n",
            "225/225 [==============================] - 51s 228ms/step - loss: 11.9306 - accuracy: 0.9622 - val_loss: 3.6466 - val_accuracy: 0.9768\n",
            "Epoch 22/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 7.1725 - accuracy: 0.9729 - val_loss: 1.4310 - val_accuracy: 0.9929\n",
            "Epoch 23/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 7.9787 - accuracy: 0.9688 - val_loss: 2.4844 - val_accuracy: 0.9911\n",
            "Epoch 24/50\n",
            "225/225 [==============================] - 51s 227ms/step - loss: 14.7256 - accuracy: 0.9542 - val_loss: 4.3825 - val_accuracy: 0.9786\n",
            "Epoch 25/50\n",
            "225/225 [==============================] - 51s 225ms/step - loss: 8.5867 - accuracy: 0.9724 - val_loss: 2.3682 - val_accuracy: 0.9857\n",
            "Epoch 26/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 5.1853 - accuracy: 0.9751 - val_loss: 11.0352 - val_accuracy: 0.9323\n",
            "Epoch 27/50\n",
            "225/225 [==============================] - 50s 220ms/step - loss: 9.8361 - accuracy: 0.9724 - val_loss: 2.6497 - val_accuracy: 0.9875\n",
            "Epoch 28/50\n",
            "225/225 [==============================] - 51s 228ms/step - loss: 7.6453 - accuracy: 0.9697 - val_loss: 0.6437 - val_accuracy: 0.9947\n",
            "Epoch 29/50\n",
            "225/225 [==============================] - 49s 218ms/step - loss: 13.6096 - accuracy: 0.9626 - val_loss: 33.4049 - val_accuracy: 0.8645\n",
            "Epoch 30/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 6.6015 - accuracy: 0.9680 - val_loss: 30.3264 - val_accuracy: 0.9037\n",
            "Epoch 31/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 9.9189 - accuracy: 0.9604 - val_loss: 1.6931 - val_accuracy: 0.9929\n",
            "Epoch 32/50\n",
            "225/225 [==============================] - 52s 233ms/step - loss: 7.6126 - accuracy: 0.9724 - val_loss: 19.2949 - val_accuracy: 0.9198\n",
            "Epoch 33/50\n",
            "225/225 [==============================] - 52s 233ms/step - loss: 12.0058 - accuracy: 0.9662 - val_loss: 3.3243 - val_accuracy: 0.9857\n",
            "Epoch 34/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 4.0467 - accuracy: 0.9786 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "225/225 [==============================] - 50s 223ms/step - loss: 6.5270 - accuracy: 0.9773 - val_loss: 0.1225 - val_accuracy: 0.9964\n",
            "Epoch 36/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 9.4659 - accuracy: 0.9724 - val_loss: 2.7704 - val_accuracy: 0.9875\n",
            "Epoch 37/50\n",
            "225/225 [==============================] - 52s 230ms/step - loss: 2.2112 - accuracy: 0.9893 - val_loss: 0.3365 - val_accuracy: 0.9964\n",
            "Epoch 38/50\n",
            "225/225 [==============================] - 50s 224ms/step - loss: 2.4430 - accuracy: 0.9871 - val_loss: 0.3229 - val_accuracy: 0.9982\n",
            "Epoch 39/50\n",
            "225/225 [==============================] - 50s 221ms/step - loss: 5.5964 - accuracy: 0.9724 - val_loss: 10.2345 - val_accuracy: 0.9554\n",
            "Epoch 40/50\n",
            "225/225 [==============================] - 51s 226ms/step - loss: 2.3820 - accuracy: 0.9893 - val_loss: 0.1907 - val_accuracy: 0.9982\n",
            "Epoch 41/50\n",
            "225/225 [==============================] - 52s 229ms/step - loss: 2.4638 - accuracy: 0.9884 - val_loss: 1.1950 - val_accuracy: 0.9929\n",
            "Epoch 42/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 2.4847 - accuracy: 0.9849 - val_loss: 0.6596 - val_accuracy: 0.9929\n",
            "Epoch 43/50\n",
            "225/225 [==============================] - 50s 223ms/step - loss: 5.4309 - accuracy: 0.9729 - val_loss: 4.0063e-06 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "225/225 [==============================] - 48s 215ms/step - loss: 1.6343 - accuracy: 0.9884 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
            "Epoch 45/50\n",
            "225/225 [==============================] - 52s 231ms/step - loss: 1.3668 - accuracy: 0.9924 - val_loss: 0.0787 - val_accuracy: 0.9982\n",
            "Epoch 46/50\n",
            "225/225 [==============================] - 51s 225ms/step - loss: 2.5954 - accuracy: 0.9875 - val_loss: 0.5639 - val_accuracy: 0.9964\n",
            "Epoch 47/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 5.0558 - accuracy: 0.9826 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 3.7387 - accuracy: 0.9831 - val_loss: 0.7453 - val_accuracy: 0.9964\n",
            "Epoch 49/50\n",
            "225/225 [==============================] - 50s 222ms/step - loss: 0.8033 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9964\n",
            "Epoch 50/50\n",
            "225/225 [==============================] - 51s 225ms/step - loss: 8.1792 - accuracy: 0.9697 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Found 100 images belonging to 2 classes.\n",
            "10/10 [==============================] - 70s 8s/step - loss: 53.0948 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[53.094818115234375, 0.8999999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define hyperparameters\n",
        "initial_lr = 0.1\n",
        "lr_decay_rate = 0.002\n",
        "momentum = 0.9\n",
        "batch_size = 10\n",
        "epochs = 50\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Replace the FC layers with new ones for binary classification (dog vs cat)\n",
        "x = Flatten()(base_model.output)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze all layers except the new FC layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "opt = SGD(learning_rate=initial_lr, momentum=momentum)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation for training images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2)  # Splitting the dataset into training and validation\n",
        "\n",
        "# all_train_path = '/content/drive/MyDrive/NNDL_HW2/HW2_Dataset/Train/'\n",
        "# all_test_path = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/'\n",
        "# train_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train'\n",
        "\n",
        "all_train_path = '/content/drive/MyDrive/NNDL_HW2_After_Augment/Train/'\n",
        "all_test_path = '/content/drive/MyDrive/NNDL_HW2_Before_Augmentation/HW2_Dataset/Test/'\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(all_train_path,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training')  # Training set\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(all_train_path,\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         class_mode='categorical',\n",
        "                                                         subset='validation')  # Validation set\n",
        "\n",
        "# Train the model with training and validation data\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "\n",
        "# Unfreeze the last CONV block\n",
        "for layer in model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the model to apply the changes\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Test data generator for evaluation\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(all_test_path ,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.evaluate(test_generator)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pXbqSbed75J2",
        "S13rZCUy1CZk"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}