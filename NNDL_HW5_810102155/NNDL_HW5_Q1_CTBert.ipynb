{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "S537-1CxiUrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpZYHqeeiTqZ",
        "outputId": "7280af5d-e653-4333-ff22-e799e2d968c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/NNDL_HW5/Test.csv'\n",
        "train_path = '/content/drive/MyDrive/NNDL_HW5/Train.csv'\n",
        "val_path = '/content/drive/MyDrive/NNDL_HW5/Val.csv'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv(test_path)\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "\n",
        "# train_df.head()\n",
        "# val_df.head()\n",
        "# test_df.sample(20)"
      ],
      "metadata": {
        "id": "TKgms39SiXeh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'] = train_df['label'].map({\"real\" : 1 , \"fake\" : 0})\n",
        "val_df['label'] = val_df['label'].map({\"real\" : 1 , \"fake\" : 0})\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JOAr_Nlwic5Q",
        "outputId": "41e430fa-ab32-4f3f-806a-36dda2edfee9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet  label\n",
              "0        1  The CDC currently reports 99031 deaths. In gen...      1\n",
              "1        2  States reported 1121 deaths a small rise from ...      1\n",
              "2        3  Politically Correct Woman (Almost) Uses Pandem...      0\n",
              "3        4  #IndiaFightsCorona: We have 1524 #COVID testin...      1\n",
              "4        5  Populous states can generate large case counts...      1\n",
              "...    ...                                                ...    ...\n",
              "6415  6416  A tiger tested positive for COVID-19 please st...      0\n",
              "6416  6417  ???Autopsies prove that COVID-19 is??� a blood...      0\n",
              "6417  6418  _A post claims a COVID-19 vaccine has already ...      0\n",
              "6418  6419  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund      0\n",
              "6419  6420  It has been 93 days since the last case of COV...      1\n",
              "\n",
              "[6420 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-765182fb-10ef-4b64-9c2b-85d6e5468443\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6415</th>\n",
              "      <td>6416</td>\n",
              "      <td>A tiger tested positive for COVID-19 please st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6416</th>\n",
              "      <td>6417</td>\n",
              "      <td>???Autopsies prove that COVID-19 is??� a blood...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6417</th>\n",
              "      <td>6418</td>\n",
              "      <td>_A post claims a COVID-19 vaccine has already ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>6419</td>\n",
              "      <td>Aamir Khan Donate 250 Cr. In PM Relief Cares Fund</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6419</th>\n",
              "      <td>6420</td>\n",
              "      <td>It has been 93 days since the last case of COV...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6420 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-765182fb-10ef-4b64-9c2b-85d6e5468443')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-765182fb-10ef-4b64-9c2b-85d6e5468443 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-765182fb-10ef-4b64-9c2b-85d6e5468443');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89493f81-86cd-43bd-979a-ba65201406c9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89493f81-86cd-43bd-979a-ba65201406c9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89493f81-86cd-43bd-979a-ba65201406c9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 6420,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1853,\n        \"min\": 1,\n        \"max\": 6420,\n        \"num_unique_values\": 6420,\n        \"samples\": [\n          325,\n          1341,\n          6026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6420,\n        \"samples\": [\n          \"Canada\\u2019s top BDSM doctor says wear a mask, leash, tight leather to prevent spread of COVID-19 #cdnpoli #COVID19 https://t.co/1E7yDlIGBD https://t.co/bffEps28Iy\",\n          \"There are 3 cases considered to have recovered from COVID-19 so our total number of active cases is 23 \\u2013 all remain in quarantine facilities.\\u200b \\u200b Our total number of confirmed cases remains at 1192 which is the number we report to the World Health Organization.\",\n          \"Heard about contact tracing but not sure what it is? It\\u2019s used by health departments to prevent the spread of #COVID19. Learn more: https://t.co/J3Txu3riWr. #SlowtheSpread https://t.co/3f8aEQCTuI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ],
      "metadata": {
        "id": "BtLG6KabifqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as functional\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "import gc\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import roc_auc_score,f1_score\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "-l8YQJU2ii8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([train_df , val_df], axis=0, ignore_index=True).drop([\"id\"], axis=1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wUjD7Og7io7n",
        "outputId": "5b2d0052-379f-41a2-a014-7cf3eb1147a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet  label\n",
              "0     The CDC currently reports 99031 deaths. In gen...      1\n",
              "1     States reported 1121 deaths a small rise from ...      1\n",
              "2     Politically Correct Woman (Almost) Uses Pandem...      0\n",
              "3     #IndiaFightsCorona: We have 1524 #COVID testin...      1\n",
              "4     Populous states can generate large case counts...      1\n",
              "...                                                 ...    ...\n",
              "8555  Donald Trump wrongly claimed that New Zealand ...      0\n",
              "8556  Current understanding is #COVID19 spreads most...      1\n",
              "8557  Nothing screams “I am sat around doing fuck al...      0\n",
              "8558  Birx says COVID-19 outbreak not under control ...      0\n",
              "8559  Another 4422 new coronavirus cases have been c...      1\n",
              "\n",
              "[8560 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce9e7712-e86a-40a4-8dbf-46fae04e9bce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8555</th>\n",
              "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8556</th>\n",
              "      <td>Current understanding is #COVID19 spreads most...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8557</th>\n",
              "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8559</th>\n",
              "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8560 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce9e7712-e86a-40a4-8dbf-46fae04e9bce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce9e7712-e86a-40a4-8dbf-46fae04e9bce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce9e7712-e86a-40a4-8dbf-46fae04e9bce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30b6404d-64ad-425a-a2a6-70733460efc4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30b6404d-64ad-425a-a2a6-70733460efc4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30b6404d-64ad-425a-a2a6-70733460efc4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8560,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8559,\n        \"samples\": [\n          \"Nashville Man Successfully Treats Coronavirus with Wedge of Lime https://t.co/JtfjPpFWZw #beer #nashville #coronavirus #epidemic #corona\",\n          \"A case of coronavirus in the Argentine province of Chaco was confirmed.\",\n          \"Donald Trump fails to distinguish between younger and older students and coronavirus risks. Early studies suggest older teens can catch and spread COVID-19 much like adults. https://t.co/hDLIVcUzSY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtKbRaPDKc43",
        "outputId": "e4f8e7b9-2abd-46da-cbcb-998a4344feac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "def preprocess(data):\n",
        "    #remove url and hashtag\n",
        "    for i in range(data.shape[0]):\n",
        "        text=data[i].lower()\n",
        "        text1=''.join([word+\" \" for word in text.split()])\n",
        "        data[i]=text1\n",
        "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*,]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    mention_regex = '@[\\w\\-]+'\n",
        "    hashtag_regex = '#[\\w\\-]+'\n",
        "    space_pattern = '\\s+'\n",
        "\n",
        "    for i in range(data.shape[0]):\n",
        "        text_string = data[i]\n",
        "        parsed_text = re.sub(hashtag_regex, '', text_string)\n",
        "        parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
        "        parsed_text = re.sub(mention_regex, '', parsed_text)\n",
        "        #remove punctuation\n",
        "        parsed_text = re.sub(r\"[{}]+\".format(punctuation), '', parsed_text)\n",
        "        parsed_text = re.sub(space_pattern, ' ', parsed_text)\n",
        "        data[i] = parsed_text\n",
        "    return data\n",
        "\n",
        "tweets = data.tweet.values\n",
        "tweets = preprocess(tweets)\n",
        "print(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-o9x6L5Klow",
        "outputId": "d3b8e319-3d0e-49b8-b154-523278c16783"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the cdc currently reports 99031 deaths in general the discrepancies in death counts between different sources are small and explicable the death toll stands at roughly 100000 people today '\n",
            " 'states reported 1121 deaths a small rise from last tuesday southern states reported 640 of those deaths '\n",
            " 'politically correct woman almost uses pandemic as excuse not to reuse plastic bag '\n",
            " ...\n",
            " 'nothing screams “i am sat around doing fuck all during lockdown” quite like confident assumption that other people are sat around doing fuck all during lockdown '\n",
            " 'birx says covid19 outbreak not under control because ‘people are on the move’ '\n",
            " 'another 4422 new coronavirus cases have been confirmed in the uk the highest daily number since 8 may its up from 4322 new cases reported on friday and the overall total nationwide now stands at 385936 read the latest here ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = data.tweet.values\n",
        "labels = data.label.values"
      ],
      "metadata": {
        "id": "bIXKUhqMLE5T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for tweet in tweets:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        tweet,\n",
        "                        # Sentence to encode.\n",
        "                        add_special_tokens = True,\n",
        "                        # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,\n",
        "                        # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        # Construct attn. masks.\n",
        "                        return_tensors = 'pt',\n",
        "                        # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "print('Original: ', tweets[10])\n",
        "print('Token IDs:', input_ids[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM9Yqse5KyPC",
        "outputId": "c57c8fdd-2662-49d2-e1ac-4a891a446141"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  take simple daily precautions to help prevent the spread of respiratory illnesses like learn how to protect yourself from coronavirus covid19 \n",
            "Token IDs: tensor([  101,  2202,  3722,  3679, 29361,  2000,  2393,  4652,  1996,  3659,\n",
            "         1997, 16464, 24757,  2066,  4553,  2129,  2000,  4047,  4426,  2013,\n",
            "        21887, 23350,  2522, 17258, 16147,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test"
      ],
      "metadata": {
        "id": "zJ3RHn0ZLXv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size],generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsd2jCGBLZtv",
        "outputId": "c234880a-33bc-4b5c-bfdf-b6f6a6235d11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,704 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            shuffle = True,\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            shuffle = False,\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "G6vkBpYtLk9u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "rhZG1uQZLs1i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"bert-base-uncased\",\n",
        "#     num_labels = 2,\n",
        "#     output_attentions = False,\n",
        "#     output_hidden_states = False,\n",
        "# )\n",
        "\n",
        "from transformers import AutoTokenizer, \\\n",
        "BertTokenizer , AutoModel\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.\\\n",
        "from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\" ,\n",
        "num_labels = 2\n",
        ")\n",
        "\n",
        "model = AutoModel.\\\n",
        "from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\" ,\n",
        "                  num_labels = 2,\n",
        "                  output_attentions = False,\n",
        "                  output_hidden_states = False\n",
        "                  )\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKSESt-ILv5h",
        "outputId": "7aca0d68-3eae-40b4-8db5-6b937272b202"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-23): 24 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "epochs = 4\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "FQuvXrJEL3_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acab0929-c69e-4ff3-835c-1995d7b0a3e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CTBert"
      ],
      "metadata": {
        "id": "RQv5wOaAf3uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CTBertGRUClassifier(nn.Module):\n",
        "    def __init__(self, model_tune):\n",
        "        super().__init__()\n",
        "        self.ctbert = model_tune\n",
        "        self.gru = nn.GRU(input_size = 768,\n",
        "                            hidden_size = 768,\n",
        "                            num_layers = 1,\n",
        "                            batch_first = True,\n",
        "                            bidirectional = True)\n",
        "        self.classifier = nn.Linear(768 * 2, 2)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask,\n",
        "                token_type_ids ):\n",
        "        bert_output = self.ctbert(input_ids = input_ids,\n",
        "                                  attention_mask = attention_mask,\n",
        "                                  token_type_ids = token_type_ids)\n",
        "\n",
        "        out, _ = self.gru(bert_output[0])\n",
        "        logits = self.classifier(out[:, 1, :])\n",
        "        return self.softmax(logits)"
      ],
      "metadata": {
        "id": "ZMtmP2-vT1xy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = CTBertGRUClassifier(model)"
      ],
      "metadata": {
        "id": "xicHP7r2Z8wI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "best_accuracy = 0\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    #Training\n",
        "    print(\"\")\n",
        "    print('Epoch {:} / {:}'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy = 0\n",
        "    model2.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        print(f\"Input size: {input_ids.size(-1)}\")  # Should print 768\n",
        "\n",
        "\n",
        "        model2.zero_grad()\n",
        "        out = model2(input_ids,\n",
        "                    attention_mask = input_mask ,\n",
        "                     token_type_ids = None\n",
        "                     )\n",
        "\n",
        "        loss = criterion(out , labels)\n",
        "        logits = out[1]\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(out , dim = 1)\n",
        "        total_train_accuracy +=  torch.sum(pred == labels).item()\n",
        "\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader.dataset)\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader.dataset)\n",
        "    print(\"  Accuracy: {}\".format(avg_train_accuracy))\n",
        "    print(\"  Training loss: {}\".format(avg_train_loss))\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    print(\"\")\n",
        "    print(\"Validation...\")\n",
        "    model2.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model2(input_ids, token_type_ids=None, attention_mask=input_mask,labels=labels)\n",
        "            loss = out[0]\n",
        "            logits = out[1]\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "        pred = torch.argmax(logits, dim = 1)\n",
        "        total_eval_accuracy += torch.sum(pred == labels).item()\n",
        "        y_true.append(labels.flatten())\n",
        "        y_pred.append(pred.flatten())\n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader.dataset)\n",
        "    print(\"  Accuracy: {}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader.dataset)\n",
        "    print(\"  Validation loss: {}\".format(avg_val_loss))\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print()\n",
        "\n",
        "    y_true = torch.cat(y_true).tolist()\n",
        "    y_pred = torch.cat(y_pred).tolist()\n",
        "    print(\"This epoch took: {:}\".format(training_time))\n",
        "    print('roc_auc score: ', roc_auc_score(y_true,y_pred))\n",
        "    print('F1 score:',f1_score(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Train Accur.': avg_train_accuracy,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print()\n",
        "\n",
        "    if avg_val_accuracy > best_accuracy:\n",
        "        best_accuracy = avg_val_accuracy\n",
        "        best_model = model\n",
        "\n",
        "print()\n",
        "print(\"=\"*10)\n",
        "print(\"Summary\")\n",
        "print(\"Total time {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh_bFqPWL9i4",
        "outputId": "5093c58d-1ca8-4758-aa5d-e8baafe934c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 / 4\n",
            "Training...\n",
            "Input size: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import CTBertForSequenceClassification, CTBertTokenizer\n",
        "# from torch.utils.data import DataLoader, Dataset\n",
        "# from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Define the CTBert model\n",
        "# model = CTBertForSequenceClassification.from_pretrained('ctbert-base')\n",
        "# tokenizer = CTBertTokenizer.from_pretrained('ctbert-base')\n",
        "\n",
        "\n",
        "\n",
        "# # Training loop\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "# loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# num_epochs = 5\n",
        "# train_losses = []\n",
        "# valid_losses = []\n",
        "# accuracies = []\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     for step , batch in enumerate(train_dataloader):\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         input_ids = batch[0].to(device)\n",
        "#         input_mask = batch[1].to(device)\n",
        "#         labels = batch[2].to(device)\n",
        "\n",
        "#         # input_ids = tokenizer(batch['tweet'], padding=True, truncation=True, return_tensors='pt').input_ids\n",
        "#         # labels = torch.tensor(batch['label'])\n",
        "\n",
        "#         outputs = model(input_ids, labels=labels)\n",
        "#         loss = outputs.loss\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         train_losses.append(loss.item())\n",
        "\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         valid_loss = 0.0\n",
        "#         predictions = []\n",
        "#         true_labels = []\n",
        "#         for step , batch in enumerate(validation_dataloader):\n",
        "#             # input_ids = tokenizer(batch['tweet'], padding=True, truncation=True, return_tensors='pt').input_ids\n",
        "#             # labels = torch.tensor(batch['label'])\n",
        "\n",
        "#             input_ids = batch[0].to(device)\n",
        "#             input_mask = batch[1].to(device)\n",
        "\n",
        "#             outputs = model(input_ids, labels=labels)\n",
        "#             valid_loss += outputs.loss.item()\n",
        "#             predictions.extend(outputs.logits.argmax(dim=-1).tolist())\n",
        "#             true_labels.extend(labels.tolist())\n",
        "\n",
        "#         valid_losses.append(valid_loss / len(validation_dataloader))\n",
        "#         accuracy = accuracy_score(true_labels, predictions)\n",
        "#         accuracies.append(accuracy)\n",
        "\n",
        "# # Plot accuracy and loss based on epoch\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(range(1, num_epochs + 1), accuracies)\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Accuracy vs. Epoch')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "# plt.plot(range(1, num_epochs + 1), valid_losses, label='Validation Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.title('Loss vs. Epoch')\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# # Test on test dataset\n",
        "# # test_dataset = CustomDataset(test_data)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# model.eval()\n",
        "# predictions = []\n",
        "# true_labels = []\n",
        "# with torch.no_grad():\n",
        "#     for batch in test_loader:\n",
        "#         input_ids = tokenizer(batch['tweet'], padding=True, truncation=True, return_tensors='pt').input_ids\n",
        "#         labels = torch.tensor(batch['label'])\n",
        "#         outputs = model(input_ids)\n",
        "#         predictions.extend(outputs.logits.argmax(dim=-1).tolist())\n",
        "#         true_labels.extend(labels.tolist())\n",
        "\n",
        "# # Confusion matrix\n",
        "# conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "# print('Confusion Matrix:')\n",
        "# print(conf_matrix)\n",
        "\n",
        "# # Precision and Recall\n",
        "# precision = precision_score(true_labels, predictions)\n",
        "# recall = recall_score(true_labels, predictions)\n",
        "\n",
        "# print(f'Precision: {precision}')\n",
        "# print(f'Recall: {recall}')\n"
      ],
      "metadata": {
        "id": "fWOli92WRLMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}